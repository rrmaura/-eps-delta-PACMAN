#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{algorithm,algpseudocode}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype true
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing onehalf
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Bayesian (
\begin_inset Formula $\epsilon,\delta$
\end_inset

) - PAC MAN
\end_layout

\begin_layout Author
Sreevidya Ayyar and Roberto-Rafael Maura-Rivero 
\end_layout

\begin_layout Standard
\noindent
In the following document, we will develop the Bayesian (
\begin_inset Formula $\epsilon,\delta$
\end_inset

) - PACMAN bandit algorithm.
\end_layout

\begin_layout Section
Motivation 
\end_layout

\begin_layout Standard
RCTs are a prevalent methodology in several fields in economics, predominantly
 in development economics.
 However, given their monetary and time costs, they are often implemented
 sparingly.
 In turn, this affects both the scope of the questions they can answer (e.g.
 how many treatments can be rolled out) and there is little consensus, besides
 economic reasoning and pre-analysis plans, as to how to better target RCTs.
\end_layout

\begin_layout Standard
At the same time, there is a growing literature on planning/designing RCTs
 in the Econometrics, Statistics and Machine-Learning literatures, which
 considers how one should choose treatment allocation mechanisms and sampling
 (
\begin_inset CommandInset citation
LatexCommand cite
key "adusumilli2021risk,dimakopoulou2017estimation,dimakopoulou2019balanced,hadad2021confidence,kasy2021adaptive,krishnamurthy2021tractable,zhan2021off"
literal "false"

\end_inset

).
 We aim to contribute to this literature by proposing one way in which experimen
ters can select which exact treatments to roll out.
 Selecting the treatment that is best-suited to studying a question, but
 that also is a good 
\begin_inset Quotes eld
\end_inset

fit
\begin_inset Quotes erd
\end_inset

 for an experimental context is not trivial and choosing well can be the
 difference between finding null versus significant effects.
 
\end_layout

\begin_layout Standard
We propose the use of multi-armed bandits as a way to pin down 
\series bold

\begin_inset Quotes eld
\end_inset

treatment-focus
\begin_inset Quotes erd
\end_inset


\series default
 in two situations: (i) experiments where we only care about learning the
 
\begin_inset Quotes eld
\end_inset

best
\begin_inset Quotes erd
\end_inset

 (highest-outcome) treatment option with as little resources as possible
 (ii) the pre-experiment stage in which the experimenter would like to narrow
 their focus to fewer treatment arms on for better-powered effect sizes
 in a subsequent full-scale RCT.
 We argue that multi-armed bandits, applied within a Bayesian framework,
 can assist the experimenter in either of these situations, at a much lower
 resource cost than standard experimentation/pilots.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
more precise motivation?
\end_layout

\begin_layout Plain Layout
1.
 RCTs are still a 
\series bold
prevalent methodology
\series default
 in the field - costly (both in monetary and time dimensions), limited in
 the scope of questions they can answer, unclear how to better target them
\end_layout

\begin_layout Plain Layout
2.
 In a growing literature on 
\begin_inset Quotes eld
\end_inset

planning/designing
\begin_inset Quotes erd
\end_inset

 RCTs, we look at the question of how one chooses the treatment(s) to roll
 out - e.g.
 suppose we know we want an informational intervention/introduce a commitment
 device, how do we decide on the exact treatment we choose to roll out (which
 can be the difference between finding null versus significant effects)
\end_layout

\begin_layout Plain Layout
3.
 We propose multi-armed bandits as a way to pin down 
\series bold
treatment focus,
\series default
 for: (i) experiments where we only care about the best treatment option
 (e.g.
 we know we need to give more info, and we want to know how) and (ii) knowing
 which treatment to focus on for better-powered effect sizes in subsequent
 RCT (e.g.
 I want to show commitment helps savings, which commitment treatment should
 I use to demonstrate this?)
\end_layout

\end_inset


\end_layout

\begin_layout Section
Setup and notation
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Similar setup to 
\begin_inset CommandInset citation
LatexCommand cite
key "kasy2021adaptive"
literal "false"

\end_inset


\end_layout

\end_inset

 Let us suppose we have 
\begin_inset Formula $k$
\end_inset

 different treatments that we believe affect binary outcome 
\begin_inset Formula $Y\in\{0,1\}$
\end_inset

.
 Suppose now that there are 
\begin_inset Formula $M$
\end_inset

 individuals in my sample (indexed by 
\begin_inset Formula $i$
\end_inset

), and that I can group my sample of individuals into 
\begin_inset Formula $T$
\end_inset

 clusters, such that 
\begin_inset Formula $M=\sum_{t=1}^{T}N_{t}$
\end_inset

.
 In each cluster, each individual is given any one of the 
\begin_inset Formula $k$
\end_inset

 treatments.
 Denote 
\begin_inset Formula $D_{it}\in K=\{1,...,k\}$
\end_inset

 as the treatment of individual 
\begin_inset Formula $i$
\end_inset

 from cluster 
\begin_inset Formula $t$
\end_inset

.
 
\end_layout

\begin_layout Standard
Now, to overlay the Bayesian framework, we will assume that for all individuals
 across all clusters, the potential outcome from being treated with treatment
 
\begin_inset Formula $d$
\end_inset

, 
\begin_inset Formula $Y_{it}^{d}$
\end_inset

, is drawn from a 
\begin_inset Formula $Bernoulli(\theta^{d})$
\end_inset

 distribution such that 
\begin_inset Formula $\{\theta_{d}\}_{d\in K}$
\end_inset

 are unknown.
 Therefore, the outcome we observe for any individual 
\begin_inset Formula $i$
\end_inset

 in cluster 
\begin_inset Formula $t$
\end_inset

 is 
\begin_inset Formula $Y_{it}=\sum_{d=1}^{k}Y_{it}^{d}\times\mathds{1}(D_{it}=d)$
\end_inset

.
 Define 
\begin_inset Formula $\hat{\theta}^{d}=\frac{1}{M}\sum_{i=1}^{M}\mathds{1}(D_{it}=d)Y_{it}$
\end_inset

 as the average outcome observed in an experiment.
 We define the experimenters goal as finding the treatment with the highest
 
\begin_inset Formula $\theta^{d}$
\end_inset

.
 Assume that SUTVA holds throughout.
 
\end_layout

\begin_layout Standard
The experimentation we consider here is sequential - in particular, at time
 
\begin_inset Formula $t$
\end_inset

, individuals cluster 
\begin_inset Formula $t$
\end_inset

 receive treatment.
 We then define success for individual 
\begin_inset Formula $i$
\end_inset

 in cluster 
\begin_inset Formula $t$
\end_inset

 as 
\begin_inset Formula $Y_{it}=1$
\end_inset

.
 Here, we introduce some notation:
\end_layout

\begin_layout Itemize
\begin_inset Formula $n_{t}^{d}=\sum_{i=1}^{N_{t}}\mathds{1}(D_{it}=d)$
\end_inset

: number of individuals assigned to treatment 
\begin_inset Formula $d$
\end_inset

 in cluster 
\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $s_{t}^{d}=\sum_{i=1}^{N_{t}}\mathds{1}(D_{it}=d,Y_{it}=1)$
\end_inset

: number of 
\begin_inset Quotes eld
\end_inset

successful
\begin_inset Quotes erd
\end_inset

 outcomes among individuals treated with treatment 
\begin_inset Formula $d$
\end_inset

 in cluster 
\begin_inset Formula $t$
\end_inset

 
\end_layout

\begin_layout Itemize
\begin_inset Formula $m_{t}^{d}=\sum_{t'=1}^{t}n_{t'}^{d}$
\end_inset

: number of individuals assigned to treatment 
\begin_inset Formula $d$
\end_inset

 so far (i.e.
 in clusters 
\begin_inset Formula $1,...,t$
\end_inset

)
\end_layout

\begin_layout Itemize
\begin_inset Formula $r_{t}^{d}=\sum_{t'=1}^{t}s_{t'}^{d}$
\end_inset

 : number of successful outcomes among individuals treated with treatment
 
\begin_inset Formula $d$
\end_inset

 so far (i.e.
 in clusters 
\begin_inset Formula $1,...,t$
\end_inset

) 
\end_layout

\begin_layout Standard
Define the 
\begin_inset Quotes eld
\end_inset

best policy
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $d^{(1)}\in\{1,...,k\}$
\end_inset

 as the one with the highest 
\begin_inset Formula $\theta^{d}$
\end_inset

.
 The experimenter's goal is to find that treatment, or a treatment almost
 as good, with high probability and with as few individuals as possible.
 To do so, we propose that the experimenter plausibly begin with priors
 
\begin_inset Formula $\theta^{d}\sim Beta(\alpha^{d},\beta^{d})$
\end_inset

, where 
\begin_inset Formula $\{\alpha^{d}\}_{d\in K}$
\end_inset

 and 
\begin_inset Formula $\{\beta^{d}\}_{d\in K}$
\end_inset

 are aggregate parameter vectors set by the experimenter (e.g.
 could simply assume a uniform prior).
 After treating cluster 
\begin_inset Formula $t$
\end_inset

, the posterior distirbution is simply 
\begin_inset Formula $\theta^{d}\sim Beta(\alpha^{d}+r_{t}^{d},\beta^{d}+(m_{t}^{d}-r_{t}^{d}))$
\end_inset

.
 Therefore, it is sufficient for the experimenter to keep track of successes
 
\begin_inset Formula $r_{t}^{d}$
\end_inset

 and failures 
\begin_inset Formula $(m_{t}^{d}-r_{t}^{d})$
\end_inset

 at any given stage in the experiment.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
some discussion of beta prior is conjugate for binomial distributions and
 so the posterior distributions on the probability of response are also
 beta distributions.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In what follows, our goal will be to provide a sequential algorithm to either:
 (i) identify 
\begin_inset Formula $d^{(1)}$
\end_inset

, or (ii) identify another treatment 
\begin_inset Formula $d$
\end_inset

 such that it is 
\begin_inset Formula $\epsilon$
\end_inset

-optimal.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
We are considering 
\begin_inset Formula $k$
\end_inset

 different treatments to improve a particular binary outcome 
\begin_inset Formula $Y\in\{0,1\}$
\end_inset

.
 We will sequentially visit villages 
\begin_inset Formula $t=1,...,T$
\end_inset

 and in each village, we will perform an experiment.
 In each village there are 
\begin_inset Formula $N_{t}$
\end_inset

 individuals (
\begin_inset Formula $i=1,...,N_{t}$
\end_inset

).
 Define 
\begin_inset Formula $M=\sum_{t=1}^{T}N_{t}$
\end_inset

 as the total sample size.
 In each village, each individual might get treated with one of the 
\begin_inset Formula $k$
\end_inset

 treatments.
 Denote 
\begin_inset Formula $D_{it}\in\{1,...,k\}$
\end_inset

 the treatment of individual 
\begin_inset Formula $i$
\end_inset

 from village 
\begin_inset Formula $t$
\end_inset

 , and their potential outcome had they taken treatment 
\begin_inset Formula $d$
\end_inset

 is 
\begin_inset Formula $Y_{it}^{d}$
\end_inset

.
 Thus, it is easy to see that 
\begin_inset Formula $Y_{it}=\sum_{d=1}^{k}Y_{it}^{d}\times\mathds{1}(D_{it}=d)$
\end_inset

.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout
Note that in each village, each individual only receives 1 treatment.
 Define 
\begin_inset Formula $\theta^{d}=\mathbb{E}(Y_{it}^{d})$
\end_inset

 as the average outcome .
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout
What we are interested is in finding the treatment with the highest outcome.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout
SUTVA holds.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout
All individuals are i.i.d.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout
For a given village 
\begin_inset Formula $t$
\end_inset

 we call:
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $n_{t}^{d}=\sum_{i=1}^{N_{t}}\mathds{1}(D_{it}=d)$
\end_inset

: number of individuals assigned to treatment 
\begin_inset Formula $d$
\end_inset

 in village 
\begin_inset Formula $t$
\end_inset

.
 
\end_layout

\begin_layout Itemize
\begin_inset Formula $s_{t}^{d}=\sum_{i=1}^{N_{t}}\mathds{1}(D_{it}=d,Y_{it}=1)$
\end_inset

: number of successful outcomes among individuals treated with treatment
 
\begin_inset Formula $d$
\end_inset

 in village 
\begin_inset Formula $t$
\end_inset

.
 
\end_layout

\begin_layout Itemize
\begin_inset Formula $m_{t}^{d}=\sum_{t'=1}^{t}n_{t'}^{d}$
\end_inset

: number of individuals assigned to treatment 
\begin_inset Formula $d$
\end_inset

 so far (i.e.
 in villages 
\begin_inset Formula $1,...,t$
\end_inset

).
\end_layout

\begin_layout Itemize
\begin_inset Formula $r_{t}^{d}=\sum_{t'=1}^{t}s_{t'}^{d}$
\end_inset

 : number of successful outcomes among individuals treated with treatment
 
\begin_inset Formula $d$
\end_inset

 so far (i.e.
 in villages 
\begin_inset Formula $1,...,t$
\end_inset

).
\end_layout

\begin_layout Plain Layout
\begin_inset Formula $Y_{it}^{d}$
\end_inset

 behaves like a Bernoulli (
\begin_inset Formula $\theta^{d}$
\end_inset

).
 Assume that we hold prior believes 
\begin_inset Formula $\theta^{d}\sim Beta(\alpha_{0}^{d},\beta_{0}^{d})$
\end_inset

 (in particular, one can have a prior uniform by assuming 
\begin_inset Formula $1=\alpha_{0}^{d}=\beta_{0}^{d}$
\end_inset

).
 In this setup, after visiting village 
\begin_inset Formula $t$
\end_inset

, the posterior is simply 
\begin_inset Formula $\theta^{d}\sim Beta(\alpha_{0}^{d}+r_{t}^{d},\beta_{0}^{d}+(m_{t}^{d}-r_{t}^{d}))$
\end_inset

.
 Therefore, it is just enough to keep track of the amount of successes 
\begin_inset Formula $r_{t}^{d}$
\end_inset

 and failures 
\begin_inset Formula $(m_{t}^{d}-r_{t}^{d})$
\end_inset

 so far.
 
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout
Define the 
\begin_inset Quotes eld
\end_inset

best policy
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $d^{(1)}\in\{1,...,k\}$
\end_inset

 as the one with the highest Average Outcome 
\begin_inset Formula $\theta^{d}=\mathbb{E}(Y_{it}^{d})$
\end_inset

.
 Our goal is to find that policy or a treatment almost as good with high
 probability with as little resources (individuals) as possible.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Is this truly well defined? I don't think so.
 I think I have to rewrite a bit the setup.
 I think it should be something like: there is a prior.
 The truth is drawn from the prior.
 We never know the truth but we know the prior.
 Something like that.
 
\series bold
sree:
\series default
 why do we need the concept of 
\begin_inset Quotes eld
\end_inset

villages
\begin_inset Quotes erd
\end_inset

 here? it feels not very useful (and immediately opens us up to external
 validity comments) - why not just there is a sample, people are treated
 differently? also, i agree it should be Bayesian from the outset, without
 definitions of potential outcomes
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Algorithm
\end_layout

\begin_layout Standard
Our bandit algorithm builds on the Median Elimination (MED) Algorithm developed
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "even2006action"
literal "false"

\end_inset

.
 Our algorithm has two advantages over the MED Algorithm:
\end_layout

\begin_layout Enumerate
MED requires a large number of individuals in the sample to provide theoretical
 guarentees on having found an 
\begin_inset Formula $\epsilon$
\end_inset

-optimal treatment.
 This is because the algorithm is unable to exploit priors placed on 
\begin_inset Formula $\{\theta_{d}\}_{d\in K}$
\end_inset

, and as a result must make use of the conservative Hoeffding's inequality
 for theoretical guarentees, which scales the number of individuals required
 with 
\begin_inset Formula $1/\epsilon^{2}$
\end_inset

.
 However, because we overlay a Bayesian set-up, we are able to explicitly
 bound probabilities using prior and posterior distirbutions over 
\begin_inset Formula $\{\theta_{d}\}_{d\in K}$
\end_inset

.
 To see this comparison, see simulations in Appendix XX.
 
\series bold
TODO: Simulations for this.
\end_layout

\begin_layout Enumerate
MED algorithm proceeds by dropping the the worst half of remaining treatments
 at each sequential stage, based on observed outcomes at the current stage.
 However, except for discarding treatments, the algorithm does not use any
 other information about the remaining treatments from previous steps.
 On the other hand, by using posterior probabilities from our Bayesian framework
, we are able to do so.
 
\end_layout

\begin_layout Enumerate
Also, while for the MED algorithm, 
\begin_inset Formula $n_{t}^{d}=n_{t}^{\tilde{d}},\forall d,\tilde{d}$
\end_inset

, with Bayesian (
\begin_inset Formula $\epsilon,\delta$
\end_inset

) - PAC MAN we allow for different amounts of individuals allocated to each
 treatment, and provide (implicit) formulation of these amounts.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
The intuition of the algorithm is fairly simple: imagine you have 
\begin_inset Formula $k=8$
\end_inset

 treatments and you go to the first village 
\begin_inset Formula $t=1$
\end_inset

.
 There, you try the 8 treatments.
 You do not have yet enough evidence to know which one is the best treatment,
 but you get enough evidence to say 
\begin_inset Quotes eld
\end_inset

the best treatment is probably among this 2
\begin_inset Quotes erd
\end_inset

.
 So you get rid of the worse half.
 Now you go to the second village 
\begin_inset Formula $t=2$
\end_inset

 and you try the 4 remaining treatments.
 Again, with this new evidence, you are still not sure which treatment is
 the best, but 
\begin_inset Quotes eld
\end_inset

it is likely one of these 2
\begin_inset Quotes erd
\end_inset

.
 So you throw away the worse half.
 Now you just have to do a last RCT in the village 
\begin_inset Formula $t=3$
\end_inset

, and there acumulate enough evidence to say 
\begin_inset Quotes eld
\end_inset

I am very sure this is the best treatment
\begin_inset Quotes erd
\end_inset

.
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Decision Rule
\end_layout

\begin_layout Standard
A key ingredient of our algorithm, following suit from MED, is the decision
 rule.
 We define it to be a function 
\begin_inset Formula $\varphi$
\end_inset

 which decides which half of the treatments move to the next sequential
 stage of the experiment.
 In our set-up, this corresponds to selecting the treatments with the highest
 (posterior) probability of being 
\begin_inset Formula $\epsilon$
\end_inset

-optimal.
 Let us state this more formally for two treatments, say 
\begin_inset Formula $d$
\end_inset

 and 
\begin_inset Formula $d'$
\end_inset

.
 We should select 
\begin_inset Formula $d$
\end_inset

 iff 
\begin_inset Formula $Pr_{t}(\theta^{d}+\epsilon<\theta^{d'})<Pr_{t}(\theta^{d'}+\epsilon<\theta^{d})$
\end_inset

, where these probabilities are posterior probabilities computed after stage
 
\begin_inset Formula $t$
\end_inset

.
 Note, it is not sufficient to check whether 
\begin_inset Formula $Pr_{t}(\theta^{d'}+\epsilon<\theta^{d})>50\%$
\end_inset

, given that it might be that both posterior probabilities exceed 
\begin_inset Formula $0.5$
\end_inset

.
 
\end_layout

\begin_layout Definition*
Given a treatment 
\begin_inset Formula $d$
\end_inset

 and a subset of treatments 
\begin_inset Formula $S\subseteq\{1,...,k\}$
\end_inset

, the set of its cumulative assigments (
\begin_inset Formula $m_{S}^{t}:=\{m_{t}^{d}\}_{d\in S}$
\end_inset

) and cumulative successes (
\begin_inset Formula $r_{S}^{t}:=\{r_{t}^{d}\}_{d\in S}$
\end_inset

), we define the set of 
\begin_inset Quotes eld
\end_inset

treatments preferable to 
\begin_inset Formula $d$
\end_inset


\begin_inset Quotes erd
\end_inset

 as: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
J^{d}(S,r_{S},m_{S},\epsilon)=\{j\in S:Pr_{t}(\theta^{j}+\epsilon<\theta^{d}|m_{S}^{t},r_{S}^{t})<Pr_{t}(\theta^{d}+\epsilon<\theta^{j}|m_{S}^{t},r_{S}^{t})\}
\]

\end_inset


\end_layout

\begin_layout Definition*
Given a subset of treatments 
\begin_inset Formula $S\subseteq\{1,...,k\}$
\end_inset

, the set of its cumulative assigments (
\begin_inset Formula $m_{S}^{t}:=\{m_{t}^{d}\}_{d\in S}$
\end_inset

) and cumulative successes (
\begin_inset Formula $r_{S}^{t}:=\{r_{t}^{d}\}_{d\in S}$
\end_inset

), define the decision rule:
\end_layout

\begin_layout Definition*
\begin_inset Formula 
\[
\varphi(S,r_{S},m_{S},\epsilon):=\{d\in S:\#J^{d}(S,r_{S},m_{S})<\frac{\#S}{2}\}
\]

\end_inset


\end_layout

\begin_layout Standard
Intuitively, what we are doing with 
\begin_inset Formula $\varphi$
\end_inset

 is that we are keeping the best half of the remaining treatment set.
 
\end_layout

\begin_layout Lemma

\series bold
Decision Rule Lemma
\end_layout

\begin_layout Lemma

\series bold
TODO: insert explicit formulation of decision rule
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Subsection
Pseudocode
\end_layout

\begin_layout Plain Layout

\series bold
TODO: impose 
\begin_inset Formula $T:=log_{2}(k)$
\end_inset

 , (or, easier to understand, impose 
\begin_inset Formula $k=2^{T}$
\end_inset

).
 In practice, people will use this for 4-6 treatments, 8 at most.
 
\end_layout

\begin_layout Plain Layout
Assume you have 2 sequences 
\begin_inset Formula $\{\epsilon_{i}\}_{i=1,\dots,T}$
\end_inset


\begin_inset Formula $\{\delta_{i}\}_{i=1,\dots,T}$
\end_inset

 s.t.
 
\begin_inset Formula $\sum_{i=1}^{T}\epsilon_{i}\leq\epsilon$
\end_inset

 and 
\begin_inset Formula $\sum_{i=1}^{T}\delta_{i}\leq\delta$
\end_inset

.
 
\end_layout

\begin_layout Plain Layout
\begin_inset Float algorithm
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Bayesian 
\begin_inset Formula $(\epsilon,\delta)$
\end_inset

 - PAC MAN
\end_layout

\end_inset


\end_layout

\begin_layout LyX-Code

\series bold
Input
\series default
 
\begin_inset Formula $\epsilon>0,\delta>0,k\in\mathbb{N}$
\end_inset

 
\end_layout

\begin_layout LyX-Code

\series bold
Initialize
\series default
 
\begin_inset Formula $S_{1}=\{1,...,k\}$
\end_inset

,
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Formula $\epsilon_{1}=\epsilon/4$
\end_inset

, 
\begin_inset Formula $\delta_{1}=\delta/2$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout LyX-Code

\series bold
For t in 1,...,T
\end_layout

\begin_deeper
\begin_layout LyX-Code
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
find n
\end_layout

\end_inset

Find 
\begin_inset Formula $\{n_{t}^{d}\}_{d\in S_{t}}$
\end_inset

such that,for all possible outcomes 
\begin_inset Formula $s_{t}^{d}$
\end_inset

, it holds that 
\begin_inset Formula $Pr(\max_{j\in S_{t}}\theta^{j}\leq\max_{i\in S_{t+1}}\theta^{i}+\epsilon_{l}|r_{S}^{t},m_{S}^{t})>1-\delta_{l}$
\end_inset


\end_layout

\begin_layout LyX-Code
(there are two possibilities: either find n with simulations or with an
 inverse function.
 It seems you need the second to get sample complexity.) 
\end_layout

\begin_layout LyX-Code

\series bold
For d in 1,...,k
\end_layout

\begin_deeper
\begin_layout LyX-Code
\begin_inset Formula $r_{t}^{d}\leftarrow$
\end_inset

Sample(d, 
\begin_inset Formula $n_{t}^{d}$
\end_inset

 times)
\end_layout

\end_deeper
\begin_layout LyX-Code
\begin_inset Formula $S_{t+1}=\varphi(S,r_{S},m_{S},\epsilon_{t})$
\end_inset


\end_layout

\begin_layout LyX-Code
\begin_inset Note Note
status collapsed

\begin_layout LyX-Code
\begin_inset Formula $\epsilon_{t+1}=\epsilon_{t}/4$
\end_inset


\end_layout

\begin_layout LyX-Code
\begin_inset Formula $\delta_{t+1}=\delta/2$
\end_inset


\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout LyX-Code
return 
\begin_inset Formula $S_{T+1}=\{\hat{d}\}$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
.
\end_layout

\begin_layout Plain Layout
.
\end_layout

\begin_layout Section
Theorems
\end_layout

\begin_layout Plain Layout
The following theorem is a Bayesian version of the Theorem 10 in 
\begin_inset CommandInset citation
LatexCommand cite
key "even2006action"
literal "false"

\end_inset

.
\end_layout

\begin_layout Theorem
Following algorithm 
\begin_inset Formula $\text{Algorithm 1}$
\end_inset

, then 
\begin_inset Formula 
\[
\forall\epsilon>0\forall\delta>0:Pr(\theta^{d^{1}}-\epsilon<\theta^{\hat{d}})>1-\delta
\]

\end_inset


\end_layout

\begin_layout Theorem

\series bold
TODO: sample complexity.
 
\end_layout

\begin_layout Lemma
For every villate 
\begin_inset Formula $t$
\end_inset

, the following holds:
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\[
Pr(\max_{j\in S_{t}}\theta^{j}\leq\max_{i\in S_{t+1}}\theta^{i}+\epsilon_{l}|r_{S}^{t},m_{S}^{t})>1-\delta_{l}
\]

\end_inset


\end_layout

\begin_layout Lemma
(here add proof of the lemma)
\end_layout

\begin_layout Plain Layout
Now that we have a proof for the Lemma, the Theorem will be proved by induction.
 We will show that 
\begin_inset Formula $Pr(\theta^{d^{1}}-\epsilon<\theta^{\hat{d}})>1-\sum_{i=1}^{T}\delta_{l},\forall T$
\end_inset

.
 Assume T=2.
 Define the following events: 
\begin_inset Formula 
\[
E=\{\theta^{d^{1}}-\epsilon<\theta^{\hat{d}}\}
\]

\end_inset


\begin_inset Formula 
\[
E_{1}=\{\max_{j\in S_{0}}\theta^{j}\leq\max_{i\in S_{1}}\theta^{i}+\epsilon_{1}\}
\]

\end_inset


\begin_inset Formula 
\[
E_{2}=\{\max_{j\in S_{1}}\theta^{j}\leq\max_{i\in S_{2}}\theta^{i}+\epsilon_{2}\}
\]

\end_inset


\begin_inset Newline newline
\end_inset

Then, it follows that 
\begin_inset Formula $E\subseteq E_{1}\cap E_{2}$
\end_inset

.
 To see this, check that 
\begin_inset Formula $\theta^{d^{1}}=\max_{j\in S_{0}}\theta^{j}\leq\max_{i\in S_{1}}\theta^{i}+\epsilon_{1}\leq\max_{i\in S_{2}}\theta^{i}+\epsilon_{2}+\epsilon_{1}=\theta^{\hat{d}}+\sum\epsilon_{l}$
\end_inset

.
 Thus,
\begin_inset Formula 
\begin{align*}
Pr(\theta^{d^{1}}-\epsilon & <\theta^{\hat{d}})=Pr(E)\\
\geq & Pr(E_{1}\cap E_{2})\\
= & 1-Pr\left((E_{1}\cap E_{2})^{c}\right)\\
= & 1-Pr\left(E_{1}^{c}\cup E_{2}^{c}\right)\\
= & 1-Pr\left(E_{1}^{c}\right)-Pr\left(E_{2}^{c}\right)+Pr\left((E_{1}\cap E_{2})^{c}\right)\\
\geq & 1-Pr\left(E_{1}^{c}\right)-Pr\left(E_{2}^{c}\right)\\
= & 1-\sum_{s_{1}=1}^{n_{1}}Pr\left(E_{1}^{c}|r,m\right)Pr(r_{1},m_{1})-\sum_{n_{2}=1}^{\tilde{n_{2}}}\sum_{s_{2}=1}^{n_{2}}Pr\left(E_{2}^{c}|r,m\right)Pr(r_{2},m_{2})\\
= & 1-\sum_{r_{1},m_{1}}Pr\left(E_{1}^{c}|r_{1},m_{1}\right)Pr(r_{1},m_{1})-\sum_{r_{2},m_{2}}Pr\left(E_{2}^{c}|r_{2},m_{2}\right)Pr(r_{2},m_{2})\\
\geq & 1-\sum_{r_{1},m_{1}}\delta_{1}Pr(r_{1},m_{1})-\sum_{r_{2},m_{2}}\delta_{2}Pr(r_{2},m_{2})\\
= & 1-\delta_{1}-\delta_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
.
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "bib"
options "plain"

\end_inset


\end_layout

\begin_layout Part*
Appendix
\end_layout

\begin_layout Section*
On Type 1 and Type 2 errors
\end_layout

\begin_layout Plain Layout
When a researcher does a hypothesis test, the probabilities of type 1 and
 type 2 errors are the following: 
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\text{Type 1 \ensuremath{\alpha=Pr(\text{reject null | }H_{0}}true })
\]

\end_inset


\begin_inset Formula 
\[
\text{Type 2 \ensuremath{\beta=Pr(\text{fail to reject | }H_{a}}true })
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Where 
\begin_inset Formula $\alpha$
\end_inset

 is defined as the significance, and (1-
\begin_inset Formula $\beta$
\end_inset

) is defined as the power.
 If the particular test is done in the context of an RCT and the null hypothesis
 is 
\begin_inset Formula $H_{0}:ATE=0$
\end_inset

 .
 Here, the events that we might care about are slightly different, as we
 are considering multiple treatments and not only one.
 Yet, under the case that one of the treatments 
\begin_inset Formula $d\in\{1,\dots,k\}$
\end_inset

 is actually a control group, i.e.
 no treatment, we will consider some possible analogous probabilities: 
\end_layout

\begin_layout Plain Layout
(WLOG 
\begin_inset Formula $d=0$
\end_inset

 is the control group )
\begin_inset Newline newline
\end_inset


\begin_inset Formula 
\[
\alpha=Pr(\theta^{\hat{d}}\neq\theta^{control}|\theta^{j}<\theta^{control}\forall j)
\]

\end_inset


\begin_inset Formula 
\[
\beta=Pr(\theta^{\hat{d}}=\theta^{control}|\theta^{j}>\theta^{control}\forall j)
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Alternatively, there are other probabilities that the researcher might care
 about.
 This ones are being discussed in the appendix.
 
\end_layout

\begin_layout Section*
Comparison with alternative bandit algorithms.
 
\end_layout

\begin_layout Plain Layout
Compare to UCB, 
\end_layout

\begin_layout Plain Layout
Compare to Thompson.
 
\end_layout

\begin_layout Section*
Prior probability vs posterior probability 
\end_layout

\begin_layout Plain Layout
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
although the prior probability of finding the best epsilon arm is 1-delta,
 note how, after doing all the experiments, the posterior probability can
 be different (depending on the observations).
 However, we should still take the same treatment because it is the one
 with highest probability of being epsilon optimal.
\end_layout

\begin_layout Plain Layout
The statement from Theorem 1 (
\begin_inset Formula $\forall\epsilon>0\forall\delta>0:Pr(\theta^{d^{1}}-\epsilon<\theta^{\hat{d}})>1-\delta$
\end_inset

) is a statement that refers to the probabilities before we have seen the
 outcome of the experiments.
 In other words, once we have comited to use this algorithm, we know that,
 with probability 
\begin_inset Formula $1-\delta$
\end_inset

, we will get an 
\begin_inset Formula $\epsilon-$
\end_inset

optimal arm down the line.
\end_layout

\begin_layout Plain Layout
However, after we have seen the data, we should update our priors and use
 the posterior probability.
 That is, after we have seen the successes and failures of the different
 treatments, the 
\series bold
posterior
\series default
 probability that our chosen treatment is 
\begin_inset Formula $\epsilon-$
\end_inset

optimal is 
\begin_inset Formula 
\[
Pr(\theta^{d^{1}}-\epsilon<\theta^{\hat{d}}|\{m_{t}^{d},r_{t}^{d}\}_{d=1,...,k})
\]

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
TODO: make some comments on how this is eassy to calculate.
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Simulations
\end_layout

\begin_layout Section*
Robustness checks.
 Simulations with different priors
\end_layout

\end_inset


\end_layout

\end_body
\end_document
